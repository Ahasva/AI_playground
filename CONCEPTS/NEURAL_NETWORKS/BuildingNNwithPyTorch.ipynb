{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be9e28d-7275-4d98-aaba-7686e9b73b08",
   "metadata": {},
   "source": [
    "# Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553eff35-1d3a-44ac-a104-b3194bb29e04",
   "metadata": {},
   "source": [
    "Geron, Aur√©lion (2025). Hands-On Machine Learning with Scikit-Learn and PyTorch: Concepts, Tools, and Techniques to Build Intelligent Systems. O'Reilly: Santa Rosa (CA)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24e8b1-31df-4371-8b93-4ecf12455edb",
   "metadata": {},
   "source": [
    "# Linear Regression with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affec130-803b-423f-9949-00214e9c09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f7d42-64a7-492d-9e83-70963ae03052",
   "metadata": {},
   "source": [
    "## Device check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f494beb6-c032-4ab2-b0c1-c50b2a574b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d401c-e893-445e-875b-a64a9d4172e0",
   "metadata": {},
   "source": [
    "## Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "723c9347-bfb1-47eb-9882-6ec0735898f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ca07ae-3709-4955-89b7-10f783f6c3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_dataset = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5335be55-72ba-49d7-86cc-34b66ed2827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.32520000e+00  4.10000000e+01  6.98412698e+00  1.02380952e+00\n",
      "   3.22000000e+02  2.55555556e+00  3.78800000e+01 -1.22230000e+02]\n",
      " [ 8.30140000e+00  2.10000000e+01  6.23813708e+00  9.71880492e-01\n",
      "   2.40100000e+03  2.10984183e+00  3.78600000e+01 -1.22220000e+02]\n",
      " [ 7.25740000e+00  5.20000000e+01  8.28813559e+00  1.07344633e+00\n",
      "   4.96000000e+02  2.80225989e+00  3.78500000e+01 -1.22240000e+02]]\n",
      "[4.526 3.585 3.521]\n"
     ]
    }
   ],
   "source": [
    "print(housing_dataset.data[:3])\n",
    "print(housing_dataset.target[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9d128-40db-4110-a56d-1bec7b6f60fa",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e37ca185-63ea-40ae-a5de-9497afcdae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing_dataset.data,\n",
    "    housing_dataset.target,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54e216-a808-4fb4-b223-eabd8353ec66",
   "metadata": {},
   "source": [
    "## Train & Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a05375f-8a7f-4cc8-9513-d514749a7337",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f035d-753e-4e72-bbd0-0fbc3f9d0895",
   "metadata": {},
   "source": [
    "## Conversion to Tensor & normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df25f12c-b436-49e4-a98a-b259cfd3a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "means = X_train.mean(dim=0, keepdims=True)\n",
    "standards = X_train.std(dim=0, keepdims=True)\n",
    "\n",
    "X_train = (X_train - means) / standards\n",
    "X_valid = (X_valid - means) / standards\n",
    "X_test = (X_test - means) / standards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a732be-cd1d-4a6c-9edf-c1a7dbaa1d47",
   "metadata": {},
   "source": [
    "## Conversion of targets to tensors\n",
    "\n",
    "Increasing the dimensionality from 1 to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffb64fa-045e-47a9-a3a2-22ded5d7f62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.FloatTensor(y_train).reshape(-1,1)\n",
    "y_valid = torch.FloatTensor(y_valid).reshape(-1,1)\n",
    "y_test = torch.FloatTensor(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d335913-7d6f-49bf-8fbf-8b3eb3e5929f",
   "metadata": {},
   "source": [
    "## Training function \n",
    "\n",
    "- with param creation\n",
    "- batch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d5e97d0-4681-408b-bfa1-18b26d2e3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(lr, epochs):\n",
    "    torch.manual_seed(42)\n",
    "    global w\n",
    "    global b\n",
    "\n",
    "    # input features\n",
    "    n_features = X_train.shape[1]\n",
    "    \n",
    "    # weights (a column vector with one weight per input dimension)\n",
    "    # initialized randomly\n",
    "    w = torch.randn((n_features, 1), requires_grad=True)\n",
    "    \n",
    "    # bias (scalar)\n",
    "    # initialized to 0\n",
    "    b = torch.tensor(0., requires_grad=True)\n",
    "    \n",
    "    learning_rate = lr\n",
    "    n_epochs = epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        # computing predictions\n",
    "        y_pred = X_train @ w + b\n",
    "\n",
    "        # MSE loss function\n",
    "        loss = ((y_pred - y_train) ** 2).mean()\n",
    "        \n",
    "        # autograd to compute gradients of the loss\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient descent step\n",
    "        with torch.no_grad():\n",
    "            b -= learning_rate * b.grad\n",
    "            w -= learning_rate * w.grad\n",
    "            b.grad.zero_()\n",
    "            w.grad.zero_()\n",
    "            \n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}; Loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b907ddb-230c-487e-803c-cf24b7bf2e2b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc86f14b-e81a-4540-811e-0ec9b9b9e46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20; Loss 16.158456802368164\n",
      "Epoch 2/20; Loss 4.8793745040893555\n",
      "Epoch 3/20; Loss 2.25522518157959\n",
      "Epoch 4/20; Loss 1.3307634592056274\n",
      "Epoch 5/20; Loss 0.9680693745613098\n",
      "Epoch 6/20; Loss 0.8142677545547485\n",
      "Epoch 7/20; Loss 0.7417045831680298\n",
      "Epoch 8/20; Loss 0.7020701169967651\n",
      "Epoch 9/20; Loss 0.6765918731689453\n",
      "Epoch 10/20; Loss 0.6577964425086975\n",
      "Epoch 11/20; Loss 0.6426151394844055\n",
      "Epoch 12/20; Loss 0.6297222971916199\n",
      "Epoch 13/20; Loss 0.6184942126274109\n",
      "Epoch 14/20; Loss 0.6085968613624573\n",
      "Epoch 15/20; Loss 0.5998216271400452\n",
      "Epoch 16/20; Loss 0.592018723487854\n",
      "Epoch 17/20; Loss 0.5850691795349121\n",
      "Epoch 18/20; Loss 0.578873336315155\n",
      "Epoch 19/20; Loss 0.573345422744751\n",
      "Epoch 20/20; Loss 0.5684100389480591\n"
     ]
    }
   ],
   "source": [
    "training(0.4, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8bf59-6468-4bbd-ab1a-32a0fd261b7f",
   "metadata": {},
   "source": [
    "## Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf735975-0973-41de-8be4-8534d6969cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:5]\n",
    "with torch.no_grad():\n",
    "    y_pred = X_new @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33358410-bfda-48cb-8c33-344b92657a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8916],\n",
      "        [1.6480],\n",
      "        [2.6577],\n",
      "        [2.7062],\n",
      "        [2.2410]])\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d748904-1e7a-4010-a46a-72f0b9d3a8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4770],\n",
       "        [0.4580],\n",
       "        [5.0000],\n",
       "        [2.1860],\n",
       "        [2.7800]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc3e943-b3e2-414e-bcaf-37f553738ef7",
   "metadata": {},
   "source": [
    "## Using higher-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fcfcb7f-7d6f-4d6c-9796-bcde0a078c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e943479b-61ad-4ab9-9ac2-c3471e007a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reimport of previously used data (see above)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "w = torch.randn((n_features, 1), requires_grad=True)\n",
    "b = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "learning_rate = 0.4\n",
    "n_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f09c868-70d9-402c-9384-efe187f11277",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model = nn.Linear(in_features=n_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2c511953-289d-4c7d-92cc-78dee5bfd6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3117], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# first the \"weights\", then the \"bias\"\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5dd91853-891c-4b0a-9466-21f564873924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4718],\n",
       "        [ 0.1131]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction with untrained model for first two instances\n",
    "# at that time params are random, hence, predictions are terrible\n",
    "model(X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e4bd6ed-6a7a-4879-b77b-ff08a6bd6963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an optimizer to update model params\n",
    "# loss func is MSE\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee340219-f386-4d28-906c-ff7494795c96",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5de68dc6-2bb4-45f7-b788-2cd091476444",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ba42d7-2205-4e96-a4b0-749c8746a013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
